Сюда я перенес текст тестового задания и прямо в тексте буду давать пояснения, что и как было проделано. Исходный текст задания скопирован из файла, мои комментарии курсивом.
## Тестовое задание ITQ Group

Нужно сделать backend-сервис по работе c документами.
Документы создаются, переводятся по статусам, по изменениям статуса ведётся история.

Дополнительно нужна утилита для массового создания документов и фоновая обработка документов пачками.
#### Стек
- Java + Spring Boot,
- PostgreSQL (Docker Compose),
- JPA/Hibernate,
- Liquibase,
- Maven/Gradle.
## Функциональные требования
### Документ
Поля: внутренний id, уникальный номер (генерируется при создании), автор, название,статус, даты создания/обновления.
Статусы: DRAFT, SUBMITTED, APPROVED.

*Сущность в DocumentService entity.Document. Статусы в енаме entity.DocumentStatus*

### История
На каждом переводе статуса сохраняйте запись: кто выполнил действие, когда, какое действие, комментарий (может быть пустым).
Действия: SUBMIT, APPROVE.
Во всех запросах на создание/перевод статуса передаётся инициатор.

*Сущность в DocumentService entity.ActivityFeedItem. Действие в енаме entity.ActionType. Связана @ManyToOne с документом.* 

*UPD. Совсем забыл про поле комментарий. Надеюсь, без него тоже можно, оно нигде не фигурирует. 
Алгоритм добавления такой -- закинуть в сущность, закинуть в дто для апдейта пачками, закинуть в дто самого активити фида, поддержать в создании активити фида и в маппере. Используется только в одном эндпойнте, api/document/full/{id}, который вторым сервисом вообще не ипользуется и вызывается только руками*

### Реестр утверждений
При успешном утверждении документа создаётся запись в реестре утверждений
(отдельная таблица/хранилище в рамках проекта).
Если запись в реестр создать не удалось, утверждение документа должно быть отменено.

*Сущность в DocumentService entity.ApprovalRegistryItem. Содержит автора изменений(строка для демоприложения) и id документа. На текущий момент лежит в отдельной таблице, JPA связей между документом и записью в реестре нет*
## API

### Создать документ

Создаёт документ в статусе DRAFT. Номер генерируется автоматически.

*Эндпойнт POST api/documents/create. Принимает дто для создания документа из двух строк. Это автор и имя*
### Получить документы

API должно уметь:
- вернуть один документ вместе с историей,
- вернуть список документов по списку id (пакетное получение).
Способ задания режима/параметров - на ваше усмотрение.
Обязательно должна быть пагинация и сортировка.

*Здесь есть три эндпойнта*
- *GET api/documents/{id} -- возвращает документ БЕЗ активити*
- *GET api/documents/full/{id} -- возвращает документ с активностью по нему.*
- *GET api/documents/batch -- возвращает пачку документов, в параметрах массив id*

*Сделал два эндпойнта на получение одного документа, чтобы избежать загрузки всего окружающего контекста сущности, когда он не нужен. Завел два разных дто на выход, DocumentDto для возврата необогащенного документа, FullDocumentDto -- для обогащенного.* 

### Отправить на согласование

Принимает список id (от 1 до 1000) и пытается перевести каждый документ DRAFT ->
SUBMITTED.
Для каждого id вернуть результат: успешно / конфликт / не найдено.
Обработка каждого документа атомарная, результаты - по каждому id (частичные успехи допустимы).

*Эндпойнт PUT api/documents/submit. На вход принимает дто StatusChangeRequest, состоящий из строки "автор" и массива id в ответе возвращает массив из id документа и строкового результата операции*

### Утвердить

Принимает список id (от 1 до 1000) и пытается перевести каждый документ SUBMITTED -> APPROVED.
Для каждого id вернуть результат: успешно / конфликт / не найдено / ошибка регистрации в реестре.
Обработка каждого документа атомарная, результаты - по каждому id.
При успешном утверждении:
- пишется запись в историю,
- создаётся запись в регистре утверждений.
Если запись в регистр не создана - утверждение документа должно быть отменено.

*Эндпойнт PUT api/documents/approve. На вход принимает дто StatusChangeRequest, состоящий из строки "автор" и массива id в ответе возвращает массив из id документа и строкового результата операции*

### Поиск документов
Фильтры: статус, автор, период дат. Вернуть список найденных документов.
Как трактовать период (по дате создания или обновления) - выберите сами и укажите в README.

*Эндпойнт GET api/documents/search.* 
*На вход принимает набор параметров фильтрации, сортировки в формате "field_name,desc" или "field_name,asc", набор параметров пагинации. Возвращает Page с документами.*
*Важно. В field_name нужно подставить именно поле класса Document. Это можно было сделать сильно получше, опять же, хорошая точка для будущего обсуждения.*

### Проверка конкурентного утверждения
Нужен отдельный API, который запускает несколько параллельных попыток утвердить один и тот же документ (параметры threads и attempts) и возвращает сводку: сколько попыток прошло успешно, сколько завершилось конфликтом/ошибкой, какой финальный статус документа.
Ожидаемое поведение: ровно одна попытка должна перевести документ в APPROVED и создать запись в реестре.
Остальные попытки должны завершиться без изменения документа и без повторной записи в регистр.

*Здесь я ступил при прочтении тествого и проектировании всей системы, поэтому эта логика находится в апи UtilService. GET api/util/concurrentApprove.
При доступе к постановщику задачи я бы конечно этот момент до написания уточнил, но здесь интерпретировал как вышло. В целом, логика реализации внутри DocumentService мало бы чем отличалась от текущей реализации в UtilService, разве что заморочек с логированием было бы меньше. Надеюсь, это некритично повлияет на оценку тествого.*

*Внутри утил сервиса создается threads потоков, каждый из которых делает attempts попыток вызвать api/documents/approve по документу. 
Тоже спорный момент, потому что еще это можно трактовать как разделение attempts попыток на threads потоков. Здесь реализовано так, на собеседовании могу рассказать, как бы я сделал иначе. 
Однократность изменения документа обеспечивается транзакционностью пачки операций в методе changeDocumentStatus класса DocumentServiceImpl в сервисе документов и оптимистической блокировкой по сущности Document. Поэтому в логах по операции будет видно, что попытки создать связанные сущности по документу будут, но все кроме одной откатятся. В целом будет threads попыток честно заапрувить с созданием всех положенных сущностей. Остальные будут отваливаться на проверке неверного изменения статуса документа.
В конце делается вызов api/documents/{id} для получения финального статуса. Для проверки созданных активностей по документу можно через swagger вызвать api/documents/full/{id}.*

## Утилита + фоновая обработка

### Утилита генерации
Сделайте отдельный модуль/утилиту, которая читает из файла параметров число N и
создаёт N документов через API сервиса.
Фоновые процессы в сервисе
	В сервисе должны работать два фоновых процесса (в отдельных потоках/задачах).
	Размер пачки должен задаваться параметром batchSize (в конфиге/файле параметров) и использоваться в обработке.

 - SUBMIT-worker
	Регулярно проверяет БД и отправляет документы со статусом DRAFT на
	согласование пачками по batchSize через пакетное API.

- APPROVE-worker
	Регулярно проверяет БД и отправляет документы со статусом SUBMITTED на
	утверждение пачками по batchSize через пакетное API.
	batchSize задаётся параметром.
	Частичные ошибки не должны останавливать обработку.
*Здесь тоже спорный момент, я сильно не уверен что правильно интерпретировал тестовое.*

*Весь этот функционал живет в отдельном микроссервисе и использует апи сервиса документов. Но это так же можно было интерпретировать как отдельный контроллер в микросервисе документов, который бы под капотом дергал те же самые сервисы. Я пошел по более сложному пути и вынес отдельный микросервис, надеюсь что либо угадал, либо некритично промахнулся.*
API UtilService
- *GET api/create. Принимает в параметрах число создаваемых документов, в цикле дергает сервис документов для создания по одному. В требованиях не было эндпойнта с созданием пачки в сервисе документов, поэтому делаем по одному. При количестве более тысячи заметно медленно получается.*
- *GET api/util/concurrentApprove. Принимает в параметрах чиcла threads, attempts, и id документа. Возвращает количество операций по их результату и итоговый статус, выдернутый отдельным запросом.*
*Фоновая работа в UtilService.*
*Две задачи, сабмит и аппрув. Конфигурируются в конфигах UtilService, настраивается частота повторения и размер искомой пачки. Таска через апи поиска пытается найти в сервисе документов пачку нужного размера в нужном статусе и перевести ее. Если не находит, отмечается в логах и ничего не делает. Если нашла, отправляет запрос на пакетное изменение и логирует результат выполнения всей пачки. Для всего однократного исполнения таски генерируется свой correlationId(подробнее в разделе с логированием)*
## Логи
*Настроил сборку логов, отправку в Loki, отображение в Grafarna.* 

*Исключительно для удобства себя и проверяющих. Так же настроил сквозное логирование по corelationId, по нему можно посмотреть связанные операции в логах DocumentService. Важный момент. В логах UtilService две кастомные метки в квадратных скобках, в логах DocumentSerivce одна. DocumentService ничего не знает про сабмиты-аппрувы, которые задаются в UtilSerivce, знает только id операции*

По логам должно быть понятно:
- сколько документов задано к созданию (N) и прогресс создания;

	*Как это посмотреть: в логах UtilService сделать поиск по содержимому "\[CREATE_DOCUMENTS\]". Это собственная метка для более удобного поиска. Если операция уже закончена, то в заголовках ответа есть X-Corelation-Id, по нему можно найти лог всей операции. Если нет, то в самых свежих логах по созданию, этот же самый id можно найти в следующей метке в квадратных скобках. Копируем вместе со скобками, ищем в содержимом лога. Так же можно посмотреть конкретные операции в DocumentSerivce, если искать correlationId в его логах.*
- время выполнения шагов: создание, каждая отправка пачки на согласование, каждая отправка пачки на утверждение;

	*Как это посмотреть: в логах UtilService сделать поиск по содержимому "\[SUBMIT_BACKGROUND\]" или "\[APPROVE_BACKGROUND\]". Здесь corelation id можно найти в следующей метке в квадратных скобках. Копируем вместе со скобками, ищем в содержимом лога для выделения конкретной пачки.*
- ход фоновой обработки (сколько обработано/осталось).

	*Как это посмотреть: в логах UtilService сделать поиск по содержимому "\[SUBMIT_BACKGROUND\]" или "\[APPROVE_BACKGROUND\]". Здесь corelation id для конкретной пачки можно найти в следующей метке в квадратных скобках. Здесь можно увидеть лог по всей пачке сразу. Для детального просмотра, corelation id копируем вместе со скобками, ищем в содержимом лога **сервиса DocumentSerivce** для выделения логов конкретной операции.*

## Ошибки и базовая валидация

- Единый формат ошибок: код + сообщение.

	*Spring придумал это за меня, в ошибочном ответе в поле status лежит код, в detail мое настроенное сообщение. В обоих сервисах сделано через @RestControllerAdvice. Все внутренние ошибки, кроме особо отмеченых отдельным обработчиком, помечаются 500 и в сообщении прилагается correlationId для расследования.* 

- “не найдено” для отсутствующего документа.

	*Отдельный обработчик для собственного исключения DocumentNotFoundException. статус 404, в detail --  id ошибки, сообщение из исключения*

- “конфликт/недопустимая операция” для недопустимого перехода статуса.

	*Как таковая это не ошибка, а элемент возвращаемого результата. Помечается result="конфликт" в итоговом массиве. Поскольку нет апи, переводящего только один документ*

- Проверка входных данных (пустые значения и т.п.).

	*Spring Validation. Ошибки невалидых аргуметов помечеются как Bad Request, как и везде прилагается id для расследования. Для sort в поиске валидации не предусмотрел, там легко ломается. По-хорошему, нужен отдельный рест с возможными настройками поиска и уже его результат использовать в поиске. Тогда будет сильно проще валидировать, а сейчас поиск просто упадет с 500, если подставить туда невалидное значение*

## Что предоставить

### Ссылка на Git репозиторий.

### Docker Compose для PostgreSQL.

### Liquibase миграции (поднятие схемы с нуля).
*Есть, три изменения. Создание всей структуры из трех таблиц, добавление версионирования документа для оптимистической блокировки, создание индекса по статусам на документах.*

### README: как запустить сервис и утилиту, как проверить прогресс по логам.

### EXPLAIN.md: пример поискового запроса + EXPLAIN (ANALYZE) + короткое пояснение по индексам.
*Пример запроса, вытащенный из Hibernate и восстановленный. Это запрос от бэкграунд таски на сабмит.
	EXPLAIN (ANALYZE)
	select d1_0.id,
       d1_0.created_by,
       d1_0.creation_date_time,
       d1_0.name,
       d1_0.status,
       d1_0.update_date_time,
       d1_0.version 
	from document d1_0 
	where d1_0.status='DRAFT'
	offset 0 
	rows fetch first 10 rows only;*
  
*Индекс только один, по статусам. Поскольку мы апи поиска дергаем при фоновых задачах, нам поможет индексирование по DRAFT и SUBMITTED. По APPROVED запрос почти всегда пойдет без индекса, потому что очень большой процент таблицы состоит из таких элементов, планировщику дешевле пойти напрямую по базе.*

### Тесты (минимум): happy-path по одному документу, пакетный submit, пакетный approve с частичными результатами, откат approve при ошибке записи в регистр.
*Тесты написаны только в микросервисе документов. Два тестовых класса, один DocumentControllerService, в нем игтеграционно протестирован пусть документа от создания до аппрува, поиск по статусам и по авторам, сабмит и выгрузка полного документа для проверки создания активити фида. Второй DocumentBatchServiceImplTest. В нем замокан сервис отвечающий за создания записей в реестре и протестирован аппрув с падением реестра, следовательно и частичный аппрув. В том же классе протестирован сабмит.* 

## Опционально

Эти пункты можно реализовать в коде или кратко описать в README:
- что бы вы поменяли, чтобы обработка одного запроса уверенно работала с 5000+ id;

	 *Использовал бы Spring Batch. внутри DocumentBatchServiceImpl. Он для этого и предназначен. Плюс, добавил бы таки пакетное создание документов, а то очень долго по одному создаются*
- как бы вы вынесли реестр утверждений в отдельную систему (отдельная БД или отдельный HTTP-сервис).

	*Если выносить в отдельную БД, то и отдельный сервис написать можно. Тем более, если этот реестр утверждений в дальнейшем собирается обрастать логикой. Например, что-то третье будет забирать записи из этого реестра за определенный период и что-то с ними делать, или уведомления какие-нибудь будут реагировать на запись в реестр.*
